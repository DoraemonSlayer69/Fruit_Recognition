{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nfrom keras import Model,models\nfrom keras import layers\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras import optimizers","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(16,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 1024,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":3,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 96, 96, 16)        1216      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 48, 48, 16)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 44, 44, 32)        12832     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 22, 22, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 18, 18, 64)        51264     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 64)          0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 5, 5, 128)         204928    \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 1024)              525312    \n_________________________________________________________________\ndense_1 (Dense)              (None, 131)               134275    \n=================================================================\nTotal params: 929,827\nTrainable params: 929,827\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Using agumented Datagenerators\ndef GetAgumentedDatagen():\n    test_datagen = ImageDataGenerator(rescale=1./255)\n    train_datagen = ImageDataGenerator(\n            rescale=1./255,\n            rotation_range=40,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True,\n            fill_mode='nearest')\n    return train_datagen,test_datagen\n\ndef Generator_with_AugmentedDatagen():\n    train_datagen,test_datagen = GetAgumentedDatagen()  \n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(100,100),\n        batch_size=100,\n        class_mode='categorical')\n    \n    test_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(100,100),\n        batch_size=100,\n        class_mode='categorical')\n    return train_generator,test_generator","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=100)","execution_count":5,"outputs":[{"output_type":"stream","text":"Found 67692 images belonging to 131 classes.\nFound 22688 images belonging to 131 classes.\nEpoch 1/100\n100/100 [==============================] - 103s 1s/step - loss: 4.6763 - acc: 0.0214\nEpoch 2/100\n100/100 [==============================] - 109s 1s/step - loss: 3.8007 - acc: 0.0870\nEpoch 3/100\n100/100 [==============================] - 100s 997ms/step - loss: 3.0051 - acc: 0.2182\nEpoch 4/100\n100/100 [==============================] - 98s 980ms/step - loss: 2.2552 - acc: 0.3659\nEpoch 5/100\n100/100 [==============================] - 98s 976ms/step - loss: 1.8375 - acc: 0.4610\nEpoch 6/100\n100/100 [==============================] - 96s 962ms/step - loss: 1.5665 - acc: 0.5305\nEpoch 7/100\n100/100 [==============================] - 96s 956ms/step - loss: 1.3997 - acc: 0.5785\nEpoch 8/100\n100/100 [==============================] - 107s 1s/step - loss: 1.3193 - acc: 0.5985\nEpoch 9/100\n100/100 [==============================] - 93s 935ms/step - loss: 1.1803 - acc: 0.6392\nEpoch 10/100\n100/100 [==============================] - 94s 938ms/step - loss: 1.0730 - acc: 0.6623\nEpoch 11/100\n100/100 [==============================] - 94s 941ms/step - loss: 1.0097 - acc: 0.6886\nEpoch 12/100\n100/100 [==============================] - 94s 941ms/step - loss: 0.9958 - acc: 0.6829\nEpoch 13/100\n100/100 [==============================] - 93s 934ms/step - loss: 0.9067 - acc: 0.7200\nEpoch 14/100\n100/100 [==============================] - 93s 930ms/step - loss: 0.8527 - acc: 0.7239\nEpoch 15/100\n100/100 [==============================] - 93s 931ms/step - loss: 0.8004 - acc: 0.7444\nEpoch 16/100\n100/100 [==============================] - 93s 930ms/step - loss: 0.7650 - acc: 0.7537\nEpoch 17/100\n100/100 [==============================] - 93s 925ms/step - loss: 0.7407 - acc: 0.7609\nEpoch 18/100\n100/100 [==============================] - 92s 919ms/step - loss: 0.7091 - acc: 0.7686\nEpoch 19/100\n100/100 [==============================] - 92s 918ms/step - loss: 0.6559 - acc: 0.7879\nEpoch 20/100\n100/100 [==============================] - 93s 930ms/step - loss: 0.6610 - acc: 0.7915\nEpoch 21/100\n100/100 [==============================] - 92s 922ms/step - loss: 0.6304 - acc: 0.7937\nEpoch 22/100\n100/100 [==============================] - 93s 935ms/step - loss: 0.6105 - acc: 0.8044\nEpoch 23/100\n100/100 [==============================] - 92s 916ms/step - loss: 0.5877 - acc: 0.8104\nEpoch 24/100\n100/100 [==============================] - 93s 934ms/step - loss: 0.6069 - acc: 0.8017\nEpoch 25/100\n100/100 [==============================] - 92s 924ms/step - loss: 0.5271 - acc: 0.8323\nEpoch 26/100\n100/100 [==============================] - 92s 916ms/step - loss: 0.4946 - acc: 0.8381\nEpoch 27/100\n100/100 [==============================] - 93s 925ms/step - loss: 0.5023 - acc: 0.8331\nEpoch 28/100\n100/100 [==============================] - 92s 917ms/step - loss: 0.4931 - acc: 0.8359\nEpoch 29/100\n100/100 [==============================] - 92s 924ms/step - loss: 0.4577 - acc: 0.8491\nEpoch 30/100\n100/100 [==============================] - 92s 916ms/step - loss: 0.4674 - acc: 0.8503\nEpoch 31/100\n100/100 [==============================] - 92s 924ms/step - loss: 0.4507 - acc: 0.8511\nEpoch 32/100\n100/100 [==============================] - 91s 914ms/step - loss: 0.4310 - acc: 0.8581\nEpoch 33/100\n100/100 [==============================] - 92s 919ms/step - loss: 0.4230 - acc: 0.8599\nEpoch 34/100\n100/100 [==============================] - 92s 924ms/step - loss: 0.4070 - acc: 0.8687\nEpoch 35/100\n100/100 [==============================] - 92s 917ms/step - loss: 0.4034 - acc: 0.8694\nEpoch 36/100\n100/100 [==============================] - 92s 921ms/step - loss: 0.3949 - acc: 0.8692\nEpoch 37/100\n100/100 [==============================] - 92s 917ms/step - loss: 0.3823 - acc: 0.8733\nEpoch 38/100\n100/100 [==============================] - 93s 925ms/step - loss: 0.3585 - acc: 0.8815\nEpoch 39/100\n100/100 [==============================] - 100s 1s/step - loss: 0.3662 - acc: 0.8770\nEpoch 40/100\n100/100 [==============================] - 92s 923ms/step - loss: 0.3553 - acc: 0.8851\nEpoch 41/100\n100/100 [==============================] - 92s 924ms/step - loss: 0.3169 - acc: 0.8946\nEpoch 42/100\n100/100 [==============================] - 93s 928ms/step - loss: 0.3583 - acc: 0.8790\nEpoch 43/100\n100/100 [==============================] - 106s 1s/step - loss: 0.3396 - acc: 0.8883\nEpoch 44/100\n100/100 [==============================] - 93s 926ms/step - loss: 0.3163 - acc: 0.8948\nEpoch 45/100\n100/100 [==============================] - 107s 1s/step - loss: 0.3294 - acc: 0.8881\nEpoch 46/100\n100/100 [==============================] - 92s 922ms/step - loss: 0.2899 - acc: 0.9030\nEpoch 47/100\n100/100 [==============================] - 92s 916ms/step - loss: 0.2983 - acc: 0.9036\nEpoch 48/100\n100/100 [==============================] - 92s 921ms/step - loss: 0.3258 - acc: 0.8899\nEpoch 49/100\n100/100 [==============================] - 92s 924ms/step - loss: 0.2876 - acc: 0.9028\nEpoch 50/100\n100/100 [==============================] - 94s 938ms/step - loss: 0.2703 - acc: 0.9091\nEpoch 51/100\n100/100 [==============================] - 95s 951ms/step - loss: 0.2785 - acc: 0.9054\nEpoch 52/100\n100/100 [==============================] - 93s 927ms/step - loss: 0.2736 - acc: 0.9042\nEpoch 53/100\n100/100 [==============================] - 93s 929ms/step - loss: 0.2703 - acc: 0.9093\nEpoch 54/100\n100/100 [==============================] - 91s 914ms/step - loss: 0.2566 - acc: 0.9145\nEpoch 55/100\n100/100 [==============================] - 92s 922ms/step - loss: 0.2771 - acc: 0.9096\nEpoch 56/100\n100/100 [==============================] - 93s 927ms/step - loss: 0.2723 - acc: 0.9102\nEpoch 57/100\n100/100 [==============================] - 96s 956ms/step - loss: 0.2590 - acc: 0.9118\nEpoch 58/100\n100/100 [==============================] - 100s 1s/step - loss: 0.2393 - acc: 0.9210\nEpoch 59/100\n100/100 [==============================] - 103s 1s/step - loss: 0.2477 - acc: 0.9176\nEpoch 60/100\n100/100 [==============================] - 100s 1s/step - loss: 0.2592 - acc: 0.9114\nEpoch 61/100\n100/100 [==============================] - 102s 1s/step - loss: 0.2368 - acc: 0.9188\nEpoch 62/100\n100/100 [==============================] - 101s 1s/step - loss: 0.2617 - acc: 0.9115\nEpoch 63/100\n100/100 [==============================] - 100s 1s/step - loss: 0.2319 - acc: 0.9225\nEpoch 64/100\n100/100 [==============================] - 100s 1s/step - loss: 0.2127 - acc: 0.9294\nEpoch 65/100\n100/100 [==============================] - 100s 997ms/step - loss: 0.2196 - acc: 0.9258\nEpoch 66/100\n100/100 [==============================] - 98s 980ms/step - loss: 0.2153 - acc: 0.9286\nEpoch 67/100\n100/100 [==============================] - 94s 941ms/step - loss: 0.2356 - acc: 0.9223\nEpoch 68/100\n100/100 [==============================] - 95s 946ms/step - loss: 0.2180 - acc: 0.9257\nEpoch 69/100\n100/100 [==============================] - 94s 937ms/step - loss: 0.1972 - acc: 0.9333\nEpoch 70/100\n100/100 [==============================] - 95s 947ms/step - loss: 0.1900 - acc: 0.9341\nEpoch 71/100\n100/100 [==============================] - 92s 919ms/step - loss: 0.2176 - acc: 0.9275\nEpoch 72/100\n100/100 [==============================] - 93s 929ms/step - loss: 0.1914 - acc: 0.9343\nEpoch 73/100\n100/100 [==============================] - 92s 924ms/step - loss: 0.1945 - acc: 0.9357\nEpoch 74/100\n100/100 [==============================] - 92s 925ms/step - loss: 0.1913 - acc: 0.9341\nEpoch 75/100\n100/100 [==============================] - 92s 923ms/step - loss: 0.1825 - acc: 0.9368\nEpoch 76/100\n100/100 [==============================] - 101s 1s/step - loss: 0.1850 - acc: 0.9372\nEpoch 77/100\n100/100 [==============================] - 92s 922ms/step - loss: 0.2003 - acc: 0.9308\nEpoch 78/100\n100/100 [==============================] - 92s 920ms/step - loss: 0.1904 - acc: 0.9357\nEpoch 79/100\n100/100 [==============================] - 93s 926ms/step - loss: 0.1851 - acc: 0.9357\nEpoch 80/100\n100/100 [==============================] - 94s 939ms/step - loss: 0.1984 - acc: 0.9314\nEpoch 81/100\n100/100 [==============================] - 93s 928ms/step - loss: 0.1836 - acc: 0.9338\nEpoch 82/100\n","name":"stdout"},{"output_type":"stream","text":"100/100 [==============================] - 93s 933ms/step - loss: 0.1791 - acc: 0.9392\nEpoch 83/100\n100/100 [==============================] - 109s 1s/step - loss: 0.1904 - acc: 0.9343\nEpoch 84/100\n100/100 [==============================] - 92s 923ms/step - loss: 0.1796 - acc: 0.9395\nEpoch 85/100\n100/100 [==============================] - 94s 939ms/step - loss: 0.1680 - acc: 0.9413\nEpoch 86/100\n100/100 [==============================] - 92s 923ms/step - loss: 0.1802 - acc: 0.9399\nEpoch 87/100\n100/100 [==============================] - 93s 927ms/step - loss: 0.1685 - acc: 0.9405\nEpoch 88/100\n100/100 [==============================] - 92s 921ms/step - loss: 0.1502 - acc: 0.9506\nEpoch 89/100\n100/100 [==============================] - 93s 928ms/step - loss: 0.1483 - acc: 0.9498\nEpoch 90/100\n100/100 [==============================] - 92s 924ms/step - loss: 0.1607 - acc: 0.9450\nEpoch 91/100\n100/100 [==============================] - 92s 925ms/step - loss: 0.1613 - acc: 0.9470\nEpoch 92/100\n100/100 [==============================] - 92s 922ms/step - loss: 0.1527 - acc: 0.9465\nEpoch 93/100\n100/100 [==============================] - 92s 917ms/step - loss: 0.1597 - acc: 0.9466\nEpoch 94/100\n100/100 [==============================] - 92s 923ms/step - loss: 0.1672 - acc: 0.9399\nEpoch 95/100\n100/100 [==============================] - 93s 929ms/step - loss: 0.1546 - acc: 0.9473\nEpoch 96/100\n100/100 [==============================] - 94s 940ms/step - loss: 0.1535 - acc: 0.9490\nEpoch 97/100\n100/100 [==============================] - 93s 935ms/step - loss: 0.1392 - acc: 0.9537\nEpoch 98/100\n100/100 [==============================] - 93s 929ms/step - loss: 0.1388 - acc: 0.9533\nEpoch 99/100\n100/100 [==============================] - 94s 938ms/step - loss: 0.1465 - acc: 0.9487\nEpoch 100/100\n100/100 [==============================] - 93s 930ms/step - loss: 0.1631 - acc: 0.9478\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model1.h5\")","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":7,"outputs":[{"output_type":"stream","text":"[0.31625816226005554, 0.9243000149726868]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using 3x3 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(16,(3,3),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(3,3),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(3,3),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(3,3),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 1024,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":7,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 98, 98, 16)        448       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 49, 49, 16)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 47, 47, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 23, 23, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 21, 21, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 10, 10, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 1024)              2098176   \n_________________________________________________________________\ndense_1 (Dense)              (None, 131)               134275    \n=================================================================\nTotal params: 2,329,891\nTrainable params: 2,329,891\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=80)","execution_count":8,"outputs":[{"output_type":"stream","text":"Found 67692 images belonging to 131 classes.\nFound 22688 images belonging to 131 classes.\nEpoch 1/80\n100/100 [==============================] - 86s 856ms/step - loss: 4.6732 - acc: 0.0374\nEpoch 2/80\n100/100 [==============================] - 83s 834ms/step - loss: 3.2311 - acc: 0.1694\nEpoch 3/80\n100/100 [==============================] - 86s 857ms/step - loss: 2.4448 - acc: 0.3049\nEpoch 4/80\n100/100 [==============================] - 85s 852ms/step - loss: 2.0338 - acc: 0.4108\nEpoch 5/80\n100/100 [==============================] - 85s 855ms/step - loss: 1.7374 - acc: 0.4934\nEpoch 6/80\n100/100 [==============================] - 82s 817ms/step - loss: 1.5032 - acc: 0.5502\nEpoch 7/80\n100/100 [==============================] - 81s 813ms/step - loss: 1.3038 - acc: 0.6079\nEpoch 8/80\n100/100 [==============================] - 80s 798ms/step - loss: 1.1783 - acc: 0.6389\nEpoch 9/80\n100/100 [==============================] - 79s 793ms/step - loss: 1.1054 - acc: 0.6619\nEpoch 10/80\n100/100 [==============================] - 78s 784ms/step - loss: 1.0080 - acc: 0.6913\nEpoch 11/80\n100/100 [==============================] - 80s 798ms/step - loss: 0.9633 - acc: 0.6958\nEpoch 12/80\n100/100 [==============================] - 77s 775ms/step - loss: 0.8919 - acc: 0.7226\nEpoch 13/80\n100/100 [==============================] - 78s 776ms/step - loss: 0.8656 - acc: 0.7278\nEpoch 14/80\n100/100 [==============================] - 77s 771ms/step - loss: 0.8051 - acc: 0.7447\nEpoch 15/80\n100/100 [==============================] - 78s 780ms/step - loss: 0.7468 - acc: 0.7676\nEpoch 16/80\n100/100 [==============================] - 76s 763ms/step - loss: 0.7196 - acc: 0.7699\nEpoch 17/80\n100/100 [==============================] - 76s 763ms/step - loss: 0.6886 - acc: 0.7823\nEpoch 18/80\n100/100 [==============================] - 76s 762ms/step - loss: 0.6482 - acc: 0.7955\nEpoch 19/80\n100/100 [==============================] - 77s 769ms/step - loss: 0.6286 - acc: 0.8007\nEpoch 20/80\n100/100 [==============================] - 76s 757ms/step - loss: 0.5831 - acc: 0.8128\nEpoch 21/80\n100/100 [==============================] - 76s 763ms/step - loss: 0.5617 - acc: 0.8231\nEpoch 22/80\n100/100 [==============================] - 75s 748ms/step - loss: 0.5425 - acc: 0.8275\nEpoch 23/80\n100/100 [==============================] - 76s 759ms/step - loss: 0.5328 - acc: 0.8283\nEpoch 24/80\n100/100 [==============================] - 76s 761ms/step - loss: 0.5121 - acc: 0.8367\nEpoch 25/80\n100/100 [==============================] - 76s 758ms/step - loss: 0.5097 - acc: 0.8295\nEpoch 26/80\n100/100 [==============================] - 75s 748ms/step - loss: 0.4809 - acc: 0.8484\nEpoch 27/80\n100/100 [==============================] - 76s 760ms/step - loss: 0.4772 - acc: 0.8476\nEpoch 28/80\n100/100 [==============================] - 82s 825ms/step - loss: 0.4353 - acc: 0.8574\nEpoch 29/80\n100/100 [==============================] - 75s 746ms/step - loss: 0.4269 - acc: 0.8610\nEpoch 30/80\n100/100 [==============================] - 77s 765ms/step - loss: 0.4008 - acc: 0.8704\nEpoch 31/80\n100/100 [==============================] - 80s 796ms/step - loss: 0.4096 - acc: 0.8702\nEpoch 32/80\n100/100 [==============================] - 75s 746ms/step - loss: 0.3858 - acc: 0.8776\nEpoch 33/80\n100/100 [==============================] - 75s 751ms/step - loss: 0.4008 - acc: 0.8688\nEpoch 34/80\n100/100 [==============================] - 77s 766ms/step - loss: 0.3744 - acc: 0.8779\nEpoch 35/80\n100/100 [==============================] - 76s 761ms/step - loss: 0.3568 - acc: 0.8829\nEpoch 36/80\n100/100 [==============================] - 87s 873ms/step - loss: 0.3388 - acc: 0.8882\nEpoch 37/80\n100/100 [==============================] - 75s 751ms/step - loss: 0.3535 - acc: 0.8856\nEpoch 38/80\n100/100 [==============================] - 75s 750ms/step - loss: 0.3277 - acc: 0.8951\nEpoch 39/80\n100/100 [==============================] - 76s 759ms/step - loss: 0.3468 - acc: 0.8854\nEpoch 40/80\n100/100 [==============================] - 75s 749ms/step - loss: 0.3052 - acc: 0.9002\nEpoch 41/80\n100/100 [==============================] - 75s 749ms/step - loss: 0.3249 - acc: 0.8939\nEpoch 42/80\n100/100 [==============================] - 76s 763ms/step - loss: 0.2917 - acc: 0.9010\nEpoch 43/80\n100/100 [==============================] - 75s 752ms/step - loss: 0.3089 - acc: 0.8967\nEpoch 44/80\n100/100 [==============================] - 75s 750ms/step - loss: 0.2704 - acc: 0.9097\nEpoch 45/80\n100/100 [==============================] - 75s 751ms/step - loss: 0.2586 - acc: 0.9179\nEpoch 46/80\n100/100 [==============================] - 75s 754ms/step - loss: 0.2661 - acc: 0.9109\nEpoch 47/80\n100/100 [==============================] - 76s 761ms/step - loss: 0.2534 - acc: 0.9185\nEpoch 48/80\n100/100 [==============================] - 76s 758ms/step - loss: 0.2751 - acc: 0.9086\nEpoch 49/80\n100/100 [==============================] - 76s 756ms/step - loss: 0.2631 - acc: 0.9125\nEpoch 50/80\n100/100 [==============================] - 76s 761ms/step - loss: 0.2537 - acc: 0.9165\nEpoch 51/80\n100/100 [==============================] - 77s 767ms/step - loss: 0.2636 - acc: 0.9126\nEpoch 52/80\n100/100 [==============================] - 76s 756ms/step - loss: 0.2355 - acc: 0.9232\nEpoch 53/80\n100/100 [==============================] - 75s 753ms/step - loss: 0.2503 - acc: 0.9190\nEpoch 54/80\n100/100 [==============================] - 76s 763ms/step - loss: 0.2447 - acc: 0.9182\nEpoch 55/80\n100/100 [==============================] - 77s 767ms/step - loss: 0.2229 - acc: 0.9264\nEpoch 56/80\n100/100 [==============================] - 75s 755ms/step - loss: 0.2165 - acc: 0.9268\nEpoch 57/80\n100/100 [==============================] - 75s 753ms/step - loss: 0.2148 - acc: 0.9278\nEpoch 58/80\n100/100 [==============================] - 76s 760ms/step - loss: 0.2108 - acc: 0.9310\nEpoch 59/80\n100/100 [==============================] - 76s 763ms/step - loss: 0.2286 - acc: 0.9251\nEpoch 60/80\n100/100 [==============================] - 75s 747ms/step - loss: 0.2126 - acc: 0.9316\nEpoch 61/80\n100/100 [==============================] - 75s 753ms/step - loss: 0.2206 - acc: 0.9272\nEpoch 62/80\n100/100 [==============================] - 76s 764ms/step - loss: 0.2063 - acc: 0.9276\nEpoch 63/80\n100/100 [==============================] - 76s 759ms/step - loss: 0.2210 - acc: 0.9255\nEpoch 64/80\n100/100 [==============================] - 75s 746ms/step - loss: 0.2067 - acc: 0.9316\nEpoch 65/80\n100/100 [==============================] - 76s 758ms/step - loss: 0.1957 - acc: 0.9356\nEpoch 66/80\n100/100 [==============================] - 76s 756ms/step - loss: 0.1872 - acc: 0.9389\nEpoch 67/80\n100/100 [==============================] - 76s 758ms/step - loss: 0.1758 - acc: 0.9423\nEpoch 68/80\n100/100 [==============================] - 75s 753ms/step - loss: 0.1676 - acc: 0.9447\nEpoch 69/80\n100/100 [==============================] - 76s 756ms/step - loss: 0.1795 - acc: 0.9379\nEpoch 70/80\n100/100 [==============================] - 76s 759ms/step - loss: 0.1717 - acc: 0.9413\nEpoch 71/80\n100/100 [==============================] - 76s 755ms/step - loss: 0.1748 - acc: 0.9390\nEpoch 72/80\n100/100 [==============================] - 75s 750ms/step - loss: 0.1850 - acc: 0.9389\nEpoch 73/80\n100/100 [==============================] - 76s 762ms/step - loss: 0.1914 - acc: 0.9379\nEpoch 74/80\n100/100 [==============================] - 76s 756ms/step - loss: 0.1730 - acc: 0.9430\nEpoch 75/80\n100/100 [==============================] - 82s 825ms/step - loss: 0.1559 - acc: 0.9505\nEpoch 76/80\n100/100 [==============================] - 76s 757ms/step - loss: 0.1762 - acc: 0.9410\nEpoch 77/80\n100/100 [==============================] - 75s 755ms/step - loss: 0.1668 - acc: 0.9437\nEpoch 78/80\n100/100 [==============================] - 75s 752ms/step - loss: 0.1581 - acc: 0.9480\nEpoch 79/80\n100/100 [==============================] - 75s 755ms/step - loss: 0.1495 - acc: 0.9479\nEpoch 80/80\n100/100 [==============================] - 75s 751ms/step - loss: 0.1591 - acc: 0.9455\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model2.h5\")","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":11,"outputs":[{"output_type":"stream","text":"[0.3055509626865387, 0.9232000112533569]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"1. ##### Using number 2 configuration from paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(8,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 1024,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":2,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 96, 96, 8)         608       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 48, 48, 8)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 44, 44, 32)        6432      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 22, 22, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 18, 18, 64)        51264     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 9, 9, 64)          0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 5, 5, 128)         204928    \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 1024)              525312    \n_________________________________________________________________\ndense_1 (Dense)              (None, 131)               134275    \n=================================================================\nTotal params: 922,819\nTrainable params: 922,819\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=80)","execution_count":null,"outputs":[{"output_type":"stream","text":"Found 67692 images belonging to 131 classes.\nFound 22688 images belonging to 131 classes.\nEpoch 1/80\n100/100 [==============================] - 97s 970ms/step - loss: 4.7160 - acc: 0.0252\nEpoch 2/80\n100/100 [==============================] - 97s 969ms/step - loss: 3.6263 - acc: 0.1072\nEpoch 3/80\n100/100 [==============================] - 95s 947ms/step - loss: 2.8264 - acc: 0.2101\nEpoch 4/80\n100/100 [==============================] - 93s 935ms/step - loss: 2.4522 - acc: 0.2879\nEpoch 5/80\n100/100 [==============================] - 103s 1s/step - loss: 2.2270 - acc: 0.3416\nEpoch 6/80\n100/100 [==============================] - 92s 919ms/step - loss: 2.0428 - acc: 0.3952\nEpoch 7/80\n100/100 [==============================] - 89s 895ms/step - loss: 1.8887 - acc: 0.4337\nEpoch 8/80\n100/100 [==============================] - 89s 894ms/step - loss: 1.7867 - acc: 0.4563\nEpoch 9/80\n100/100 [==============================] - 88s 880ms/step - loss: 1.6826 - acc: 0.4742\nEpoch 10/80\n100/100 [==============================] - 88s 883ms/step - loss: 1.5704 - acc: 0.5241\nEpoch 11/80\n100/100 [==============================] - 104s 1s/step - loss: 1.4684 - acc: 0.5446\nEpoch 12/80\n100/100 [==============================] - 87s 873ms/step - loss: 1.4228 - acc: 0.5578\nEpoch 13/80\n100/100 [==============================] - 86s 865ms/step - loss: 1.2847 - acc: 0.6017\nEpoch 14/80\n100/100 [==============================] - 85s 855ms/step - loss: 1.1824 - acc: 0.6285\nEpoch 15/80\n100/100 [==============================] - 86s 858ms/step - loss: 1.1444 - acc: 0.6459\nEpoch 16/80\n100/100 [==============================] - 86s 860ms/step - loss: 1.0164 - acc: 0.6823\nEpoch 17/80\n100/100 [==============================] - 85s 850ms/step - loss: 0.9686 - acc: 0.6958\nEpoch 18/80\n100/100 [==============================] - 86s 863ms/step - loss: 0.9294 - acc: 0.7022\nEpoch 19/80\n100/100 [==============================] - 86s 863ms/step - loss: 0.8797 - acc: 0.7282\nEpoch 20/80\n100/100 [==============================] - 86s 864ms/step - loss: 0.8776 - acc: 0.7234\nEpoch 21/80\n100/100 [==============================] - 87s 872ms/step - loss: 0.8188 - acc: 0.7395\nEpoch 22/80\n 97/100 [============================>.] - ETA: 2s - loss: 0.7945 - acc: 0.7433","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model3.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using number 3 configuration from paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(32,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 1024,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model4.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using number 4 configuration from paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(16,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(16,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 1024,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model5.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using number 5 configuration from paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(16,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 1024,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model6.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using number 6 configuration from paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(16,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 1024,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model7.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using number 7 configuration from paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(16,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 1024,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model8.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using number 8 configuration from paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(16,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 1024,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model9.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using number 9 configuration from paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(16,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 512,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model10.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using number 10 configuration from paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(16,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 512,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### using a combination of 5x5 and 3x3 filter"},{"metadata":{"trusted":true},"cell_type":"code","source":"#using 5x5 kernel\ntrain_dir = \"../input/fruits/fruits-360/Training\"\ntest_dir = \"../input/fruits/fruits-360/Test\"\n\nnum_files = os.listdir(train_dir)\nnum_files_test = os.listdir(test_dir)\nnumber_classes = len(num_files)\n\nnetwork = models.Sequential()\nnetwork.add(layers.Conv2D(16,(5,5),activation='relu',input_shape=(100,100,3)))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(32,(3,3),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(64,(3,3),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Conv2D(128,(5,5),activation='relu'))\nnetwork.add(layers.MaxPooling2D((2,2),strides=2))\nnetwork.add(layers.Flatten())\nnetwork.add(layers.Dense(units = 1024,activation='relu'))\nnetwork.add(layers.Dense(units=number_classes,activation='softmax'))\n\nnetwork.compile(optimizer=optimizers.Adam(lr=1e-4),loss='categorical_crossentropy',metrics=['acc'])\nnetwork.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator,test_generator = Generator_with_AugmentedDatagen()\n\n#Training the model\nhistory = network.fit_generator(train_generator,steps_per_epoch=100,epochs=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network.save(\"Fruits-360_model12.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = network.evaluate_generator(test_generator,steps=100)\nprint(score)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}